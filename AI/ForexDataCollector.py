import MetaTrader5 as mt5
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import os
from typing import Dict, List, Optional
import logging

class RawCandlestickCollector:
    """
    ‡∏£‡∏∞‡∏ö‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏î‡∏¥‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI Training
    ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ OHLCV + Time context
    ‡πÑ‡∏°‡πà‡∏°‡∏µ Feature Engineering - ‡πÉ‡∏´‡πâ AI ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏≠‡∏á
    """
    
    def __init__(self, symbol: str = "XAUUSD.c"):
        self.original_symbol = symbol
        self.symbol = None
        self.timeframes = {
            'M1': mt5.TIMEFRAME_M1,
            'M5': mt5.TIMEFRAME_M5,
            'M30': mt5.TIMEFRAME_M30,
            'H1': mt5.TIMEFRAME_H1,
            'H4': mt5.TIMEFRAME_H4,
            'D1': mt5.TIMEFRAME_D1
        }
        
        # Setup logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # Initialize MT5 and find working symbol
        if self._initialize_mt5():
            self.symbol = self._find_working_symbol()
    
    def _initialize_mt5(self) -> bool:
        """‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MT5"""
        if not mt5.initialize():
            self.logger.error("MT5 initialization failed")
            return False
        
        self.logger.info("MT5 initialized successfully")
        return True
    
    def _find_working_symbol(self) -> str:
        """‡∏´‡∏≤‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á"""
        gold_symbols = [
            self.original_symbol, "XAUUSD", "XAUUSD.c", "XAUUSDm", 
            "GOLD", "GOLDm", "GOLD.c", "#XAUUSD"
        ]
        
        self.logger.info("üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ...")
        
        for symbol in gold_symbols:
            symbol_info = mt5.symbol_info(symbol)
            if symbol_info is None:
                continue
                
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            test_rates = mt5.copy_rates_from_pos(symbol, mt5.TIMEFRAME_H1, 0, 10)
            if test_rates is not None and len(test_rates) > 0:
                self.logger.info(f"‚úÖ ‡πÉ‡∏ä‡πâ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå: {symbol}")
                return symbol
        
        self.logger.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
        return None
    
    def get_raw_candlestick_data(self, timeframe: str, bars: int = 10000) -> pd.DataFrame:
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏î‡∏¥‡∏ö - ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ OHLCV
        
        Args:
            timeframe: M1, M5, M30, H1, H4, D1
            bars: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            
        Returns:
            DataFrame: Pure OHLCV data with datetime index
        """
        if timeframe not in self.timeframes:
            raise ValueError(f"Invalid timeframe. Use: {list(self.timeframes.keys())}")
        
        mt5_timeframe = self.timeframes[timeframe]
        rates = mt5.copy_rates_from_pos(self.symbol, mt5_timeframe, 0, bars)
        
        if rates is None:
            self.logger.error(f"Failed to get rates for {self.symbol} {timeframe}")
            return pd.DataFrame()
        
        # Convert to DataFrame
        df = pd.DataFrame(rates)
        df['time'] = pd.to_datetime(df['time'], unit='s')
        df.set_index('time', inplace=True)
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Raw OHLCV
        raw_columns = ['open', 'high', 'low', 'close', 'tick_volume']
        df = df[raw_columns]
        
        # Rename columns ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
        df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Time Context ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Technical Analysis)
        df = self._add_time_context(df)
        
        self.logger.info(f"üìä {timeframe}: ‡∏î‡∏∂‡∏á‡πÑ‡∏î‡πâ {len(df):,} ‡πÅ‡∏ó‡πà‡∏á (Raw OHLCV)")
        return df
    
    def _add_time_context(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Time Context ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Technical Analysis
        """
        df = df.copy()
        
        # === Basic Time Information ===
        df['Hour'] = df.index.hour
        df['Day_of_week'] = df.index.dayofweek  # 0=Monday, 6=Sunday
        df['Day_of_month'] = df.index.day
        df['Month'] = df.index.month
        df['Year'] = df.index.year
        
        # === Market Session (GMT+0) ===
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏•‡∏≤‡∏î - ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà analysis
        df['Is_asian_hours'] = ((df['Hour'] >= 0) & (df['Hour'] < 9)).astype(int)
        df['Is_european_hours'] = ((df['Hour'] >= 8) & (df['Hour'] < 17)).astype(int)
        df['Is_us_hours'] = ((df['Hour'] >= 13) & (df['Hour'] < 22)).astype(int)
        
        # === Weekend Markers ===
        df['Is_monday'] = (df['Day_of_week'] == 0).astype(int)
        df['Is_friday'] = (df['Day_of_week'] == 4).astype(int)
        df['Is_weekend'] = (df['Day_of_week'] >= 5).astype(int)
        
        return df
    
    def get_multi_timeframe_raw_data(self, bars_per_tf: Dict[str, int] = None) -> Dict[str, pd.DataFrame]:
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Raw ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ó‡∏°‡πå‡πÄ‡∏ü‡∏£‡∏°
        
        Args:
            bars_per_tf: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏ó‡∏°‡πå‡πÄ‡∏ü‡∏£‡∏°
        """
        if bars_per_tf is None:
            # Default bars - ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô AI
            bars_per_tf = {
                'D1': 2000,    # ~5-6 ‡∏õ‡∏µ
                'H4': 10000,   # ~4-5 ‡∏õ‡∏µ  
                'H1': 20000,   # ~2-3 ‡∏õ‡∏µ
                'M30': 30000,  # ~1-2 ‡∏õ‡∏µ
                'M5': 50000,   # ~6 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
                'M1': 60000    # ~6 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå
            }
        
        self.logger.info("üì¶ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Raw Candlestick ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ó‡∏°‡πå‡πÄ‡∏ü‡∏£‡∏°")
        
        raw_data = {}
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ó‡∏°‡πå‡πÄ‡∏ü‡∏£‡∏°‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏õ‡πÄ‡∏•‡πá‡∏Å (stable)
        for tf in ['D1', 'H4', 'H1', 'M30', 'M5', 'M1']:
            if tf in bars_per_tf:
                bars = bars_per_tf[tf]
                
                try:
                    df = self.get_raw_candlestick_data(tf, bars)
                    
                    if not df.empty:
                        raw_data[tf] = df
                        coverage_days = (df.index.max() - df.index.min()).days
                        self.logger.info(f"‚úÖ {tf}: {len(df):,} ‡πÅ‡∏ó‡πà‡∏á | {coverage_days} ‡∏ß‡∏±‡∏ô")
                    else:
                        self.logger.warning(f"‚ùå {tf}: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                        
                except Exception as e:
                    self.logger.error(f"‚ùå {tf}: Error - {str(e)}")
                    continue
                
                time.sleep(0.3)  # ‡∏û‡∏±‡∏Å‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
        
        return raw_data
    
    def prepare_ai_raw_dataset(self, save_to_file: bool = True) -> Dict[str, pd.DataFrame]:
        """
        ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Raw ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI Training
        ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ OHLCV + Time Context
        """
        if not self.symbol:
            self.logger.error("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
            return {}
        
        self.logger.info("üöÄ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Raw Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI Training")
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Raw
        raw_data = self.get_multi_timeframe_raw_data()
        
        if not raw_data:
            self.logger.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
            return {}
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        cleaned_data = {}
        for tf, df in raw_data.items():
            # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
            df_clean = self._clean_raw_data(df, tf)
            cleaned_data[tf] = df_clean
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
        if save_to_file:
            folder_name = f"raw_ai_data_{self.symbol.replace('.', '_').replace('/', '_')}"
            self._save_raw_dataset(cleaned_data, folder_name)
        
        self.logger.info("‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Raw Dataset ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå")
        return cleaned_data
    
    def _clean_raw_data(self, df: pd.DataFrame, timeframe: str) -> pd.DataFrame:
        """
        ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Raw
        """
        df_clean = df.copy()
        
        # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ 0 ‡∏´‡∏£‡∏∑‡∏≠ NaN
        df_clean = df_clean.dropna()
        df_clean = df_clean[(df_clean[['Open', 'High', 'Low', 'Close']] > 0).all(axis=1)]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô
        # High >= max(Open, Close) ‡πÅ‡∏•‡∏∞ Low <= min(Open, Close)
        valid_candles = (
            (df_clean['High'] >= df_clean[['Open', 'Close']].max(axis=1)) &
            (df_clean['Low'] <= df_clean[['Open', 'Close']].min(axis=1))
        )
        df_clean = df_clean[valid_candles]
        
        # ‡∏•‡∏ö outliers (‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 10% ‡πÉ‡∏ô‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        price_change = abs(df_clean['Close'].pct_change())
        df_clean = df_clean[price_change < 0.1]
        
        self.logger.info(f"üßπ {timeframe}: ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î {len(df):,} ‚Üí {len(df_clean):,} ‡πÅ‡∏ó‡πà‡∏á")
        return df_clean
    
    def _save_raw_dataset(self, data: Dict[str, pd.DataFrame], folder: str):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Raw Dataset"""
        if not os.path.exists(folder):
            os.makedirs(folder)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å CSV ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ó‡∏°‡πå‡πÄ‡∏ü‡∏£‡∏°
        for tf, df in data.items():
            filename = f"{folder}/{self.symbol}_{tf}_raw.csv"
            df.to_csv(filename)
            self.logger.info(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {filename}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset Summary
        summary = {
            'dataset_type': 'Raw Candlestick Data for AI Training',
            'symbol': self.symbol,
            'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'description': 'Pure OHLCV data without feature engineering',
            'data_range': {
                'start': min([df.index.min() for df in data.values()]).strftime('%Y-%m-%d'),
                'end': max([df.index.max() for df in data.values()]).strftime('%Y-%m-%d')
            },
            'timeframes': {},
            'total_bars': sum([len(df) for df in data.values()]),
            'columns': list(data[list(data.keys())[0]].columns.tolist())
        }
        
        for tf, df in data.items():
            coverage_days = (df.index.max() - df.index.min()).days
            summary['timeframes'][tf] = {
                'bars': len(df),
                'columns': df.shape[1],
                'start': df.index.min().strftime('%Y-%m-%d %H:%M'),
                'end': df.index.max().strftime('%Y-%m-%d %H:%M'),
                'coverage_days': coverage_days,
                'file': f"{self.symbol}_{tf}_raw.csv"
            }
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Summary JSON
        import json
        with open(f'{folder}/raw_dataset_info.json', 'w') as f:
            json.dump(summary, f, indent=2)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á README
        readme = f"""# Raw Candlestick Dataset - {self.symbol}

## üéØ ‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏î‡∏¥‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô AI Trading
**‡πÑ‡∏°‡πà‡∏°‡∏µ Feature Engineering** - ‡πÉ‡∏´‡πâ AI ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏´‡∏≤ Pattern ‡πÄ‡∏≠‡∏á

## üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ
- **Symbol**: {self.symbol}
- **Total Bars**: {summary['total_bars']:,}
- **Date Range**: {summary['data_range']['start']} ‡∏ñ‡∏∂‡∏á {summary['data_range']['end']}
- **Timeframes**: {', '.join(data.keys())}

## üìã Columns
```
{', '.join(summary['columns'])}
```

## üéØ Philosophy
> "‡πÉ‡∏´‡πâ AI ‡∏´‡∏≤ Pattern ‡πÄ‡∏≠‡∏á ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏≠‡∏Å‡∏°‡∏±‡∏ô‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤"

### ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ:
- Technical Indicators (RSI, MACD, etc.)
- Chart Patterns (Head & Shoulders, etc.)
- Support/Resistance levels
- Trend analysis

### ‚úÖ ‡∏°‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞:
- Pure OHLCV data
- Time context (Hour, Day, Session)
- Multiple timeframes

## üß† Next Steps
1. **Train Candlestick Recognition Model**
   - ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô
   - ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à Market Psychology ‡∏à‡∏≤‡∏Å‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô

2. **Multi-Timeframe Analysis**
   - ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ó‡∏°‡πå‡πÄ‡∏ü‡∏£‡∏°
   - ‡∏´‡∏≤ Context ‡∏à‡∏≤‡∏Å‡πÑ‡∏ó‡∏°‡πå‡πÄ‡∏ü‡∏£‡∏°‡πÉ‡∏´‡∏ç‡πà

3. **Pattern Discovery**
   - ‡πÉ‡∏´‡πâ AI ‡∏´‡∏≤ Pattern ‡∏ó‡∏µ‡πà‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏≠‡∏≤‡∏à‡∏°‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô
   - ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Theory

4. **Decision Making**
   - ‡πÄ‡∏ó‡∏£‡∏ô AI ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à Buy/Sell/Hold
   - ‡πÉ‡∏ä‡πâ Reinforcement Learning

Generated: {summary['creation_date']}
"""
        
        with open(f'{folder}/README.md', 'w') as f:
            f.write(readme)
        
        self.logger.info(f"üìã ‡∏™‡∏£‡πâ‡∏≤‡∏á Documentation ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢: {folder}/")

# === Usage Example ===
if __name__ == "__main__":
    print("üéØ Raw Candlestick Data Collector for AI Training")
    print("=" * 50)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á collector
    collector = RawCandlestickCollector("XAUUSD.c")
    
    if not collector.symbol:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
        exit()
    
    print(f"‚úÖ ‡πÉ‡∏ä‡πâ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå: {collector.symbol}")
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Raw
    print("\nüöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Raw Dataset...")
    raw_dataset = collector.prepare_ai_raw_dataset()
    
    if raw_dataset:
        print(f"\nüéâ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Raw {collector.symbol}")
        print("=" * 60)
        
        total_bars = 0
        for tf, df in raw_dataset.items():
            days = (df.index.max() - df.index.min()).days
            total_bars += len(df)
            
            print(f"üìä {tf:>3}: {len(df):>8,} ‡πÅ‡∏ó‡πà‡∏á | {days:>4} ‡∏ß‡∏±‡∏ô | {df.shape[1]} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
            print(f"     üìÖ {df.index.min().strftime('%Y-%m-%d')} ‡∏ñ‡∏∂‡∏á {df.index.max().strftime('%Y-%m-%d')}")
        
        print("=" * 60)
        print(f"üìä ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_bars:,} ‡πÅ‡∏ó‡πà‡∏á")
        print(f"üìÅ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô: raw_ai_data_{collector.symbol.replace('.', '_')}/")
        
        # ‡πÅ‡∏™‡∏î‡∏á sample data
        sample_df = list(raw_dataset.values())[0]
        print(f"\nüìã Columns: {list(sample_df.columns)}")
        print(f"üìà Sample Data (latest 3 rows):")
        print(sample_df.tail(3)[['Open', 'High', 'Low', 'Close', 'Volume']])
        
        print(f"\n‚úÖ Raw Dataset ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI Training!")
        print(f"üß† ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ: ‡∏™‡∏≠‡∏ô AI ‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô")
        
    else:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")